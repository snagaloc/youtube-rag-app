# ğŸ¥ YouTube RAG Assistant â€” Production - Style  GenAI Engineer Architecture

### LangChain Â· OpenAI Â· ChromaDB Â· Streamlit Â· Modular Architecture

An end-to-end **Retrieval-Augmented Generation (RAG)** system that allows users to ask grounded questions about any YouTube video using transcript-based semantic search.

This repository demonstrates **production-style GenAI engineering practices**, including modular design, metadata-aware retrieval, vector databases, and context-grounded LLM responses.

---

# ğŸš€ Features

âœ… Accepts both **YouTube URL** and **Video ID**
âœ… Automatic transcript extraction
âœ… Language detection support (optional extension)
âœ… Semantic chunking using RecursiveCharacterTextSplitter
âœ… OpenAI embeddings + vector search (ChromaDB)
âœ… Context-aware answers using RAG pipeline
âœ… Clean architecture (UI + services + prompts separation)
âœ… Streamlit interactive UI

---

# ğŸ§  Architecture Overview

User Question
â†“
Streamlit UI
â†“
YouTube Transcript Service
â†“
Chunking + Metadata
â†“
Embeddings (OpenAI)
â†“
Chroma Vector Store
â†“
Retriever
â†“
LLM (Context-Grounded Prompt)
â†“
Answer

---

# ğŸ§± Project Structure

youtube_rag_app/

app.py                 â†’ Streamlit UI
services/
â€ƒyoutube_service.py   â†’ Fetch transcript logic
â€ƒrag_service.py       â†’ Chunking + embedding + retrieval pipeline
â€ƒutils.py             â†’ Helpers (video id extraction, formatting)

prompts/
â€ƒprompts.py           â†’ Prompt templates

requirements.txt
README.md

---

# âš™ï¸ Installation

## 1ï¸âƒ£ Clone Repository

git clone https://github.com/YOUR_USERNAME/youtube-rag-app.git
cd youtube-rag-app

---

## 2ï¸âƒ£ Create Virtual Environment

python -m venv venv
venv\Scripts\activate

---

## 3ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

---

## 4ï¸âƒ£ Configure API Key

Create a `.env` file:

OPENAI_API_KEY=your_key_here

---

# â–¶ï¸ Run Application

streamlit run app.py

Open browser:

http://localhost:8501

---

# ğŸ” How the RAG Pipeline Works

### Step 1 â€” Transcript Ingestion

The system extracts YouTube transcripts via youtube-transcript-api.

### Step 2 â€” Semantic Chunking

Transcript text is split into smaller contextual chunks using RecursiveCharacterTextSplitter.

### Step 3 â€” Embeddings

Each chunk is converted into semantic vectors using:

OpenAI â†’ text-embedding-3-small

### Step 4 â€” Vector Indexing

Chunks are stored in ChromaDB for fast similarity search.

### Step 5 â€” Retrieval

User queries retrieve relevant transcript chunks using semantic similarity.

### Step 6 â€” LLM Answer Generation

The LLM receives:

Context + Question

Prompt rules enforce:

* Answer only from transcript context
* Avoid hallucination
* Structured output

---

# ğŸ§ª Example Questions

Summarize this video
What is DeepMind?
Explain Medallion Architecture mentioned in the video
What topics were discussed around minute 20?

---

# ğŸ›  Tech Stack

Python
LangChain
OpenAI API
ChromaDB
Streamlit
YouTube Transcript API

---

# ğŸ§© Engineering Decisions

### Why RAG instead of fine-tuning?

* No retraining required
* Lower cost
* Dynamic knowledge updates

### Why ChromaDB?

* Local persistence
* Lightweight vector storage
* Fast setup for GenAI apps

### Why Modular Structure?

* Easier testing
* Cleaner architecture
* Future backend scalability (FastAPI / Agents)

---

# ğŸ“ˆ Future Improvements

Multi-language translation pipeline
Hybrid retrieval (BM25 + Vector)
Multi-query retrieval
Agent workflows (LangGraph)
Token usage observability
Docker deployment

---

# ğŸ‘¨â€ğŸ’» Author

Built as part of a **Senior GenAI Engineering / Architect learning roadmap** focused on:

RAG Systems
LLM Architecture
Production AI Design Patterns

---

# â­ If You Like This Project

Give it a â­ on GitHub!
